{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Trees using scikit-learn - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Following the toy example we saw in the previous lesson, we'll now build a decision tree for a more complex dataset. This lab covers all major areas of standard machine learning practice , from data acquisition to evaluation of results. We'll continue to use the scikit-learn and pandas libraries to conduct this analysis, following the same structure we saw in the previous lesson.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use pandas to prepare the data for the scikit-learn decision tree algorithm\n",
    "- Train the classifier with a training dataset and evaluate performance using different measures\n",
    "- Visualize the decision tree and interpret the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCI Banknote Authentication Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we'll work with a popular dataset for classification called the \"UCI Bank Note Authentication Dataset'. This Data were extracted from images that were taken from genuine and forged banknotes! The notes were first digitized, followed by a numerical transformation using DSP techniques. The final set of engineered features are all continuous in nature, meaning that our dataset consists entirely of floats, with no strings to worry about. If you're curious about how the dataset was created, you can Google UCI to learn about feature engineering in detail!\n",
    "\n",
    "We have the following attributes in the dataset. \n",
    "\n",
    "1. __Variance__ of Wavelet Transformed image (continuous) \n",
    "2. __Skewness__ of Wavelet Transformed image (continuous) \n",
    "3. __Kurtosis__ of Wavelet Transformed image (continuous) \n",
    "4. __Entropy__ of image (continuous) \n",
    "5. __Class__ (integer) - Target/Label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary Libraries\n",
    "- Import necessary libraries as we saw in previous lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Data\n",
    "\n",
    "Now, we'll load our dataset in a DataFrame, perform some basic EDA, and generally get a feel for the data we'll be working with.\n",
    "\n",
    "- Read the file `\"data_banknote_authentication.csv\"` as a pandas dataframe. Note that there is no header information in this dataset.\n",
    "- Assign column names 'Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class' to dataset in the given order.\n",
    "- View the basic statistics and shape of dataset.\n",
    "- Check for frequency of positive and negative examples in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.read_csv('data_banknote_authentication.csv',\n",
    "                 names=['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variance     Skewness     Curtosis      Entropy        Class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    762\n",
       "1    610\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class frequency of target variable \n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Features and Labels, Training and Test Data\n",
    "\n",
    "Now we need to create our feature set `X` and labels `y`. \n",
    "- Create `X` and `y` by selecting the appropriate columns from the dataset\n",
    "- Create a 80/20 split on the dataset for training/testing. Use `random_state=10` for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels\n",
    "X = df.drop(['Class'], axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an 80/20 split\n",
    "X_train, X_test , y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Classifier and Make Predictions\n",
    "- Create an instance of `DecisionTreeClassifier` with `random_state=10` for reproducibility\n",
    "- Fit the training data to the model \n",
    "- USe the trained model to make predictions with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a DT classifier\n",
    "classifier = DecisionTreeClassifier(random_state=10)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check Predictive Performance\n",
    "\n",
    "We can now use different evaluation measures to check the predictive performance of the classifier. \n",
    "- Check the accuracy , AUC and create a confusion matrix \n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 97.81818181818181\n",
      "AUC = 0.978\n",
      "Confusion Matrix:\n",
      " [[149   3]\n",
      " [  3 120]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy , AUC and Confusion matrix \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score = {acc*100}\")\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(f\"AUC = {round(roc_auc,3)}\")\n",
    "\n",
    "# Create a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretation: This decision tree model is surprisingly accurate!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Interpretation: This decision tree model is surprisingly accurate!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Re-grow the Tree Using Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO in the above example, we used all default settings for decision tree classifier. The default impurity criterion in scikit-learn is the Gini impurity. We can change it back to entropy by passing in `criterion='entropy'` argument to the classifier in the training phase. \n",
    "- Repeat the above tasks for training, evaluation and visualization using Entropy measure. (\n",
    "- Compare and interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 99.63636363636364\n",
      "AUC = 0.997\n",
      "Confusion Matrix:\n",
      " [[151   1]\n",
      " [  0 123]]\n"
     ]
    }
   ],
   "source": [
    "classifier2 = DecisionTreeClassifier(criterion='entropy', random_state=10)\n",
    "classifier2.fit(X_train, y_train)\n",
    "y_pred = classifier2.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score = {acc*100}\")\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(f\"AUC = {round(roc_auc,3)}\")\n",
    "\n",
    "# Create a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n',cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional \n",
    "\n",
    "- We discussed earlier that decision trees are very sensitive towards outliers. Try to identify and remove/fix any possible outliers in the dataset. \n",
    "- Check the distributions of the data. Is there any room for normalization/scaling of data ? Apply these techniques and see if it improves upon accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.Entropy, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Curtosis'] < 6)\n",
    "         & (df['Skewness'] > -10)\n",
    "         & (df['Variance'] > -5)\n",
    "         & (df['Entropy'] > -4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels\n",
    "X = df2.drop(['Class'], axis=1)\n",
    "y = df2.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an 80/20 split\n",
    "X_train, X_test , y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 99.49748743718592\n",
      "AUC = 0.996\n",
      "Confusion Matrix:\n",
      " [[118   1]\n",
      " [  0  80]]\n"
     ]
    }
   ],
   "source": [
    "classifier2 = DecisionTreeClassifier(criterion='entropy', random_state=10)\n",
    "classifier2.fit(X_train, y_train)\n",
    "y_pred = classifier2.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score = {acc*100}\")\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(f\"AUC = {round(roc_auc,3)}\")\n",
    "\n",
    "# Create a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n',cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we looked at growing a decision tree for banknote authentication dataset which is composed of extracted continuous features from photographic data. We looked at different stages of the experiment including data acquisition, training, prediction and evaluation. We also looked at growing trees using entropy vs. gini impurity criteria. In following lessons, we shall look at some more such pre-train tuning techniques for ensuring an optimal classifier for learning and prediction.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
